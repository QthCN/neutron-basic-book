## 网络namespace的实现

在Neutron的纯软件方案中，网络的namespace起到了非常重要的作用。比如Neutorn中的路由器就是通过一个独立的namespace配合其中的路由、iptables等来实现的。这里我们来将一下网络namespace的实现。

关于namespace可以参考下下面的文章：

* http://coolshell.cn/articles/17010.html
* http://coolshell.cn/articles/17029.html

传统上如果我们要在一台物理机上隔离出一个独立的环境，在其中运行某个服务的时候，一般都是通过软件虚拟化的方式实现的。比如笔者需要在一台物理机上建立一个虚拟路由器，可以通过：

1. 建立一台虚拟机，拥有两个虚拟网卡
2. 在虚拟机中配置好路由表

此时这个虚拟机就能看成是一个拥有两个物理口的路由器了，每个虚拟网卡可以外接一个子网，实现子网间路由。但这样做有一些缺陷，主要是：

1. 虚拟化后的性能没有直接在物理机上的性能好
2. 启动、停止一个虚拟机耗时较长

于是在很久之前就有人在Unix、Linux上实现namespace这么一个功能了。虚拟化能满足需求，但是开销太大，那就不用虚拟化，在代码层面上做个隔离嘛。所以namespace在实现上最重要的就是做了这个隔离。下面这个例子可以帮助大家在代码层面理解namespace的实现。在没有引入namespace之前，获取当前系统上网卡名字的接口可能是类似于下面的实现：

```
interfaces = ["eth0", "eth1"]

def get_interfaces():
	return interfaces
```

在有了namespace后，实现变为：

```
class NS(object):

	def __init__():
		self.interfaces = []
		
	def add_interface(ifname):
		self.interfaces.append(ifname)
		
	def get_interfaces():
		return self.interfaces

def get_interfaces(ns):
	return ns.get_interfaces()
	
ns_apple = NS()
ns_apple.add_interface("eth0")
ns_apple.add_interface("eth1")

ns_pear = NS()
ns_pear.add_interface("eth0")

# apple namespace下的网卡列表
apple_ifs = get_interfaces(ns_apple)
# pear namespace下的网卡列表
pear_ifs = get_interfaces(ns_pear)

```

是不是很简单？确实内核如果要支持namespace的话，主要的改动就是在以前老的函数中增加一个namespace的参数代表这个函数会在哪个namespace下进行操作。对于内核社区来说增加namespace的很大的一个工作量就是修改所有涉及到的函数。

我们来看网络部分的namespace的实现。上面的例子中一个NS对象就是一个namespace，对于内核来说，一个进程如何知道自己在哪个namespace下操作是依赖进程task_struct的nsproxy属性来判断的：

```
/* namespaces */
    struct nsproxy *nsproxy;

/* 
 * A structure to contain pointers to all per-process
 * namespaces - fs (mount), uts, network, sysvipc, etc.
 *
 * The pid namespace is an exception -- it's accessed using
 * task_active_pid_ns.  The pid namespace here is the
 * namespace that children will use.
 *
 * 'count' is the number of tasks holding a reference.
 * The count for each namespace, then, will be the number
 * of nsproxies pointing to it, not the number of tasks.
 * 
 * The nsproxy is shared by tasks which share all namespaces.
 * As soon as a single namespace is cloned or unshared, the
 * nsproxy is copied.
 */
struct nsproxy {
    atomic_t count;
    struct uts_namespace *uts_ns;
    struct ipc_namespace *ipc_ns;
    struct mnt_namespace *mnt_ns;
    struct pid_namespace *pid_ns_for_children;
    struct net       *net_ns;
};
extern struct nsproxy init_nsproxy;
```

我们可以把nsproxy简单的类比成我们上面举例的NS类。只不过内核对nsproxy做了细分，分成了uts、ipc、mnt、pid以及net这几个namespace，我们的网络namespace就是这里的net。也就是说原来的代码一个进程如果想要查看当前环境下的网卡列表是通过调用get_interfaces查看的获取的话，此时则是通过get_interfaces(task_struct->nsproxy->net_ns)来获取了。

来看下net_ns。这个结构体在include/net/net_namespace.h文件中。下面是其一些属性：

```
struct net {
    ...
    //namespace的链表
    struct list_head    list; 
    //用来串net_device的链表    
    struct list_head    dev_base_head;
    struct hlist_head   *dev_name_head;
    struct hlist_head   *dev_index_head;
    //每个namespace自己的lo链表
    struct net_device       *loopback_dev;
    ...
};
```

在本书的前面章节介绍了通过ip命令来操作网络namespace的相关命令。下面我们通过ip命令的源码来看下网络namespace的一些实现。当敲下ip netns add XXX后，代码会进入到：

```
if (matches(*argv, "add") == 0)
    return netns_add(argc-1, argv+1);
```

这里netns_add负责创建一个网络namespace，实现为：

```
static int netns_add(int argc, char **argv)
{
    /* This function creates a new network namespace and
     * a new mount namespace and bind them into a well known
     * location in the filesystem based on the name provided.
     *
     * The mount namespace is created so that any necessary
     * userspace tweaks like remounting /sys, or bind mounting
     * a new /etc/resolv.conf can be shared between uers.
     */
    char netns_path[MAXPATHLEN];
    const char *name;
    int fd;
    int made_netns_run_dir_mount = 0;
     
    if (argc < 1) {
        fprintf(stderr, "No netns name specified\n");
        return -1;
    }  
    name = argv[0];
 
    snprintf(netns_path, sizeof(netns_path), "%s/%s", NETNS_RUN_DIR, name);
 
    if (create_netns_dir())
        return -1;
```

首先这里会在NETNS_RUN_DIR下建立一个目录，NETNS_RUN_DIR的定义为：

```
#define NETNS_RUN_DIR "/var/run/netns"
```

比如这个例子，我们可以看到ip命令为我们建立了目录：

```
[root@dev ~]# ip netns add X
[root@dev ~]# cd /var/run/netns/
[root@dev netns]# ll
总用量 0
-r--r--r--. 1 root root 0 7月   4 21:11 X
```

此时netns_add还没有为我们真正建立namespace，所以我们继续分析其实现（这里会跳过mnt部分）：

```
/* Create the filesystem state */
fd = open(netns_path, O_RDONLY|O_CREAT|O_EXCL, 0);
if (fd < 0) {
    fprintf(stderr, "Cannot create namespace file \"%s\": %s\n",
        netns_path, strerror(errno));
    return -1;
}
close(fd);
if (unshare(CLONE_NEWNET) < 0) {
    fprintf(stderr, "Failed to create a new network namespace \"%s\": %s\n",
        name, strerror(errno));
    goto out_delete;
}
```

注意这里的unshare以及传给它的CLONE_NEWNET，unshare由内核提供，其会建立一个新的网络namespace并将当前进程的task_struct->nsproxy->net_ns指向它。因此从此刻开始这个进程所执行的所有设计网络相关的命令就都在这个新的namespace中了。至于unshare建立新的namespace会做些什么操作我们下面会看到。

另外这里读者可能会有个疑问，如果unshare会让task_struct->nsproxy->net_ns指向一个新的namespace，那么原来task_struct->nsproxy->net_ns指向的是什么呢？如果原来task_struct->nsproxy->net_ns指向的也是一个namespace，比如namespace A，那么为什么ip netns list命令看不到这个namespace而只能看到新创建的namespace呢？其实这里是被ip命令欺骗了，其list命令的实现为：

```
static int netns_list(int argc, char **argv)
{
    struct dirent *entry;
    DIR *dir;
    int id;
     
    dir = opendir(NETNS_RUN_DIR);
    if (!dir)
        return 0;
         
    while ((entry = readdir(dir)) != NULL) {
        if (strcmp(entry->d_name, ".") == 0)
            continue;
        if (strcmp(entry->d_name, "..") == 0)
            continue;
        printf("%s", entry->d_name);
        if (ipnetns_have_nsid()) {
            id = get_netnsid_from_name(entry->d_name);
            if (id >= 0)
                printf(" (id: %d)", id);
        }
        printf("\n");
    }
    closedir(dir);
    return 0;
}
```

可以看到，ip netns list只会列出NETNS_RUN_DIR下的那些namespace，而不会列出内核中所有的namespace。其实内核在启动的时候会建立一个默认的网络namespace DEFAULT_NETNS，如果没有特别操作的话，进程一般都是使用这个DEFAULT_NETNS作为网络的namespace的。也就是task_struct->nsproxy->net_ns一般都是指向DEFAULT_NETNS。

现在我们知道新建立一个网络namespace可以通过unshare来实现。我们来看下一个新的网络namespace的建立代码。切入点为：

```
int copy_namespaces(unsigned long flags, struct task_struct *tsk)
{  
    struct nsproxy *old_ns = tsk->nsproxy;
    struct user_namespace *user_ns = task_cred_xxx(tsk, user_ns);
    struct nsproxy *new_ns;
         
    if (likely(!(flags & (CLONE_NEWNS | CLONE_NEWUTS | CLONE_NEWIPC |
                  CLONE_NEWPID | CLONE_NEWNET)))) {
        get_nsproxy(old_ns);
        return 0;
    }
         
    if (!ns_capable(user_ns, CAP_SYS_ADMIN))
        return -EPERM;
             
    /* 
     * CLONE_NEWIPC must detach from the undolist: after switching
     * to a new ipc namespace, the semaphore arrays from the old
     * namespace are unreachable.  In clone parlance, CLONE_SYSVSEM
     * means share undolist with parent, so we must forbid using
     * it along with CLONE_NEWIPC.
     */
    if ((flags & (CLONE_NEWIPC | CLONE_SYSVSEM)) ==
        (CLONE_NEWIPC | CLONE_SYSVSEM))
        return -EINVAL;
 
    new_ns = create_new_namespaces(flags, tsk, user_ns, tsk->fs);
    if (IS_ERR(new_ns))
        return  PTR_ERR(new_ns);
 
    tsk->nsproxy = new_ns;
    return 0;
}
```
create_new_namespaces建立了新的namespace。来看下涉及网络的部分：

```
new_nsp->net_ns = copy_net_ns(flags, user_ns, tsk->nsproxy->net_ns);
if (IS_ERR(new_nsp->net_ns)) {
    err = PTR_ERR(new_nsp->net_ns);
    goto out_net;
}

struct net *copy_net_ns(unsigned long flags,
            struct user_namespace *user_ns, struct net *old_net)
{  
    struct net *net;
    int rv;
     
    if (!(flags & CLONE_NEWNET))
        return get_net(old_net);
     
    net = net_alloc();
    if (!net)
        return ERR_PTR(-ENOMEM);
 
    get_user_ns(user_ns);
 
    mutex_lock(&net_mutex);
    rv = setup_net(net, user_ns);
    if (rv == 0) {
        rtnl_lock();
        list_add_tail_rcu(&net->list, &net_namespace_list);
        rtnl_unlock();
    }
    mutex_unlock(&net_mutex);
    if (rv < 0) {
        put_user_ns(user_ns);
        net_drop_ns(net);
        return ERR_PTR(rv);
    }
    return net;
}
```

如果CLONE_NEWNET没有设置，那么就用老的网络的namespace（也就是新的进程继承老的进程的namespace，你老的能看到几个网卡我新的同样能看到，因为我们都是指向同一个结构体）。否则则是先调用net_alloc获取个新的net结构体，然后通过setup_net初始化后将它放到内核全局的net_namespace_list链表下。net_namespace_list定义为：

```
LIST_HEAD(net_namespace_list);
EXPORT_SYMBOL_GPL(net_namespace_list);
```

所有对于一个新的网络的namespace，初始化工作主要由setup_net实现。其代码为：

```
/*
 * setup_net runs the initializers for the network namespace object.
 */
static __net_init int setup_net(struct net *net, struct user_namespace *user_ns)
{
    /* Must be called with net_mutex held */
    const struct pernet_operations *ops, *saved_ops;
    int error = 0;
    LIST_HEAD(net_exit_list);
         
    atomic_set(&net->count, 1);
    atomic_set(&net->passive, 1);
    net->dev_base_seq = 1;
    net->user_ns = user_ns;
    idr_init(&net->netns_ids);
 
    list_for_each_entry(ops, &pernet_list, list) {
        error = ops_init(ops, net);
        if (error < 0)
            goto out_undo;
    }
out:
    return error;
 
out_undo:
    /* Walk through the list backwards calling the exit functions
     * for the pernet modules whose init functions did not fail.
     */
    list_add(&net->exit_list, &net_exit_list);
    saved_ops = ops;
    list_for_each_entry_continue_reverse(ops, &pernet_list, list)
        ops_exit_list(ops, &net_exit_list);
 
    ops = saved_ops;
    list_for_each_entry_continue_reverse(ops, &pernet_list, list)
        ops_free_list(ops, &net_exit_list);
 
    rcu_barrier();
    goto out;
}
```

这里主要是调用了pernet_list的ops来执行各种初始化。内核中一些子系统、模块可以通过register_pernet_device注册一些需要在一个新的namespace建立时执行的函数放在parent_list上，此时一个新的网络namespace被建立的时候就能调用这些函数。比如在net_dev_init这里可以看到如下代码：

```
/* The loopback device is special if any other network devices
 * is present in a network namespace the loopback device must
 * be present. Since we now dynamically allocate and free the
 * loopback device ensure this invariant is maintained by
 * keeping the loopback device as the first device on the
 * list of network devices.  Ensuring the loopback devices
 * is the first device that appears and the last network device
 * that disappears.
 */
if (register_pernet_device(&loopback_net_ops))
    goto out;
```
loopback_net_ops会在新的namespace中建立一个lo的net_device，所以我们的namespace中就都能看到lo设备的存在。

需要说明的是虽然上面的分析都是通过进程的task_struct来引到网络的namespace结构体上，但是实际上这个结构体是独立存在在内核中的。比如net_device有一个nd_net指针指向了某个网络的namespace结构体，表示这个net_device属于哪个namespace。

网络namespace的基本实现原理就是上面这些。最后有一个需要注意的就是目前还不是所有网络相关的代码都能感知到namespace的存在。也就是说一些代码目前还没有来得及改成本节开始举例中有ns参数的形式。笔者曾经遇到过一个物理机的ip_forward系统变量设置为1但是namespace中依然为0造成的故障，现在我们知道这个故障的原因是对于ip_forward这个系统变量在网络的namespace中已经支持造成的。如果网络的namespace还不能支持系统变量，那么类似于get_system_var这种函数就还不能传递ns参数，于是所有namespace取到的系统参数应该都是同一个，也就不会存在ip_forward不一致的情况了。那么如何快速简单粗略的定位目前内核的网络namespace代码被哪些模块感知了呢？可以查看网络namespace的net这个结构体的属性，比如net结构体里有sysctl相关的结构体：

```
struct netns_ipv4   ipv4;

struct netns_ipv4 {
#ifdef CONFIG_SYSCTL
    struct ctl_table_header *forw_hdr;
    struct ctl_table_header *frags_hdr;
    struct ctl_table_header *ipv4_hdr;
    struct ctl_table_header *route_hdr;
    struct ctl_table_header *xfrm4_hdr;
#endif
```

因此我们相关系统变量能够感知到网络namespace的存在。